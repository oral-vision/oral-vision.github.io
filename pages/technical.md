---
layout: page
title: How It Works
description: Hardware design, system architecture, and AI pipeline
image: assets/images/technical.png
show-tile: true
tile_order: 3
hide_image: false
---

OralVision is a system that combines a custom handheld imaging device with reinforced machine learning to enable early detection of oral diseases. The handheld device is manufactured utilizing a combination of commercial off-the-shelf parts and 3D printing to balance design robustness with costs. The deviceâ€™s control center is a XIAO-ESP32-C6 microcontroller, a low-power yet powerful solution to reduce costs while maintaining the technical capabilities of larger, more expensive controllers. The image is taken using an Arducam 5MP Camera Shield with SPI compatibility for high-bandwidth image data transfer to the microcontroller. Additionally, an anti-fog nano coating is applied to the camera lens to prevent moisture in the mouth from harming the internal components. To minimize user error, the entire device uses a single medical-grade momentary push button to control image streaming and capturing. The power is regulated using a 5V voltage regulator to prevent voltage spikes when processing image data. The regulator also accepts multiple power sources, including USB-C (with a port for easy charging access), AA batteries, and solar power (for extremely low-income areas with minimal electrical infrastructure). The device also ships with rechargeable Nickel Metal Hydride batteries to prevent thermal runaway during transportation. The entire device is then enveloped in a sterilization wrap to prevent bacteria and microbes from entering the device. The device housing is created using PLA+, a material with substantially more robust mechanical properties and higher print quality when compared to traditional PLA at the same cost.
OralVision employs a three-layer distributed architecture optimized for low-latency medical imaging while considering the physical and resource constraints of its target clients. First, the sensing layer consists of an Arducam OV5642 5-MP image sensor and a 140-degree camera lens to maximize coverage and image quality while minimizing image capture latency. Next, the processing layer consists of the ESP32-C6 with a WiFi 802.11b/g/n transceiver to wirelessly transmit image data to the inference layer utilizing a Flask WiFi Access Point on a Raspberry Pi 5. The Pi has 16GB of SDRAM for model loading and communicates with the device using Flask and the RESTful API. Once the image data is transmitted, the Raspberry Pi analyzes the image with TensorFlow Lite and outputs the possible diseases and their probabilities.
Instead of simply illuminating abnormal tissue, OralVision takes multiple photos of a patient's oral cavity and feeds them into a comprehensive federated neural network that our company developed and trained. Our innovation has the capability to provide highly accurate clinical diagnoses and iteratively refine model parameters based on aggregated HIPAA-compliant patient data, giving us a significant edge over market competitors that haven't even considered integrating machine learning with intraoral diagnostics yet. In addition, OralVision utilizes cost-effective hardware, enabling our company to produce it at a relatively lower marginal cost and sell it at a highly competitive price that's more accessible to underserved communities. The only notable disadvantage that OralVision has in comparison with existing solutions is the fact that the device is quite bulky and not ergonomically optimized. However, we have plans to make the device frame sleeker to maximize patient comfort in future prototypes.