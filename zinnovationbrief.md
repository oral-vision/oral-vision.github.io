1. Elevator Pitch:
Pitch your innovation, sharing its essence, impact, customers and business potential.
Oral cavity cancers are highly treatable when caught early, but almost 70% of cases are diagnosed too late due to clinical uncertainty and a lack of accessible screening tools, leading to over 170,000 deaths annually. OralVision is an intraoral, deep-learning-based diagnostic device designed to change this unfortunate reality. The device captures high resolution images of the oral cavity and analyzes them in real time using a pre-trained neural network that can identify malignant tissue patterns oblivious to the naked eye. By integrating noninvasive imaging with advanced artificial intelligence, our innovation is capable of providing physicians with highly accurate diagnostic insights, allowing for earlier clinical referrals and therapeutic intervention. Moreover, with its use of inexpensive, yet powerful components, OralVision has the potential to be mass produced and distributed at a much lower marginal cost than existing solutions, contributing to improved 5-year survival rates, especially in marginalized low-income communities.
2. Team: How did your team form? What role will each team member play? What motivated you to make this innovation? What special capabilities, resources or experiences do your team members bring?
Team OralVision was formed in response to rising rates of oral cavity and pharyngeal cancers in North Texas, which have disproportionately affected members of our community living underprivileged medical deserts like South Dallas with limited access to proper diagnostic technologies. We saw the hardships that these people had to go through firsthand from volunteer experiences, motivating us to pursue an engineering-based solution that could make a meaningful impact on public health systems in these areas. Alan brings nearly 2 years of experience in oncology research and business management, allowing him to effectively facilitate model pretraining and product commercialization. Zayan brings significant expertise in the development of deep-learning models using TensorFlow for previous projects, making him well suited to facilitate development of OralVision's ML model and user interface. Abdullah contributes over 3 years of experience in CAD, electrical engineering, and prototype design, positioning him to lead the design of OralVision's hardware.
3. Opportunity: What issue or pain point does your innovation address?
Over the past decade, oral cavity cancer rates have skyrocketed across the United States as a result of increased human papillomavirus (HPV) exposure. While oral cancer is quite treatable when caught early, nearly 70% of cases are diagnosed in the later stages, largely because malignant oral mucosa lesions are often misdiagnosed as visually similar benign conditions like canker sores and fibromas. In fact, a recent study published in MDPI's Healthcare journal showed that 54% of oral cancer cases were misdiagnosed by dental practitioners and senior students, exemplifying the scale of diagnostic errors in the field of oral oncology. This diagnostic gap is only exacerbated by inequitable access to advanced healthcare technologies in underprivileged communities, with over 30% of people living in these areas reported to have limited access to proper dental care. Even in Federally Qualified Health Centers (FQHCs), which are dedicated to serving the healthcare needs of low-income populations, cancer screening rates are substantially lower than the national average. Unfortunately, this combination of diagnostic uncertainty and healthcare disparities leads to over 170,000 deaths annually across the world, raising debates over whether existing diagnostic solutions are adequate to address the silent threat that oral cavity cancers pose. Most oral cancer imaging devices utilize fluorescence spectroscopy to illuminate abnormal tissue, but these methods cannot differentiate between benign and malignant lesions. Therefore, final diagnoses ultimately depend on unreliable visual examinations or expensive biopsy procedures that are often not feasibly accessible for people living in impoverished areas. Moreover, these fluorescence-based devices can cost over $2,000 per unit, further alienating clinics that serve low-income communities from utilizing affordable diagnostic tools. OralVision aims to ameliorate these issues by offering a highly accurate, deep-learning-based imaging tool that is over 3 times cheaper than alternatives, ultimately contributing to decreased oral cavity cancer rates.
4. Innovation: Describe your innovation, its design and your technology. How does it work? What is new or proprietary about the innovation? How does it meet needs and resolve pain points? What impact does your innovation create for individual users and for humankind? Describe this qualitatively and quantitatively. How can new or proprietary aspects be protected and made valuable by one or more methods such as a patent, trade secret, copyright or otherwise competitively defensible configuration?
The control center for OralVision’s imaging device is a XIAO-ESP32-C6 microcontroller, a cheap, yet powerful solution to reduce production costs while maintaining the technical capabilities of larger, more expensive controllers. The image is taken using an OV5642 5MP image sensor with SPI compatibility for high-bandwidth data transfer to the microcontroller. In addition, an anti-fog nano coating is applied to the camera lens to prevent moisture in the mouth from harming the internal components. To minimize user error, the entire system uses a single medical-grade momentary push button to control image streaming and capturing. The power is regulated using a 5V voltage regulator to prevent current spikes when alternate charging methods are used. The regulator accepts multiple power sources, including USB-C (with a port for easy charging access), AA batteries, and solar power (for extremely low-income areas with minimal electrical infrastructure). The device also ships with rechargeable nickel-metal hydride batteries to prevent thermal runaway during transportation. The entire imaging system is also encased in a sterilization wrap to prevent bacteria and microbes from entering the device. The prototype’s housing is held together using a snap-fit mechanism for easy access to the electronics for battery replacements and software updates. These components are visualized by the computer model we've provided in Attachment 2.
For communication protocols between the imaging device and the machine learning interface, we used SPI and Wi-Fi (see Attachment 2). We chose SPI over UART and I^2C because of its ability to transmit high-resolution intraoral images continuously with minimal latency. The device transfers images to our ML interface wirelessly via Wi-Fi 5, where our federated learning model processes the images and transmits diagnostic results to the screen on our Raspberry Pi 5 human-machine interface (HMI). When a device processes an image, it systematically alters neural parameters to improve the accuracy of our main model, which clients can download from our website periodically for software updates. 
Furthermore, our ML model performs significantly better than prominent market competitors. We attained an overall intraoral identification accuracy of 87.15%, with an industry-high ROC-AUC Score of 0.9417 and a F1 score of 0.8655 during our testing. By contrast, VELScope, our main competitor, was only able to attain a much lower accuracy of 53% in experimental trials. 
We used various techniques while developing our ML model to obtain a high accuracy. First, we augmented our limited, publicly-available training data using geometric and lighting transformations. Next, we employed DenseNet121 as our model architecture due to its enhanced ability to form neural connections. We also incorporated neuron dropping to increase reliability and prevent overfitting. Furthermore, we used L2 regularization to ensure that our model was not overfitted to our data by ensuring no specific decision points were given too much weight in the decision-making process.  Finally, we utilized multi-step gradual training to maximize accuracy by initially training only a head layer, but later unfreezing the rest of the model for parameter updates.
However, we realized that solely basing our model on publicly available training data would allow competitors to easily create comparable models using similar techniques. Therefore, we transformed our standard ML model into a federated learning model that allows for constant inputs of new, HIPAA-compliant patient data that competitors cannot copy. This shift to federated learning allows us to negate biases that may have been present in our training data while staying ahead of major market competitors.
OralVision lowers the ceiling for oral disease diagnosis by streamlining the processing pipeline. Users are not required to have significant training to use the device, as the minimal control system, in conjunction with the software-level abstraction, ensures a smooth user experience. Moreover, OralVision was designed with the limitations of its target audience in mind, as it will be shipped with features such as rechargeable batteries and solar panels, bypassing barriers to usage like compromised electrical infrastructure in nearly 30% of underprivileged areas. With its highly affordable pricing, OralVision has the potential to revolutionize diagnostics in low-income communities, where less than 20% of clinics have access to adequate diagnostic technologies, and boost 5-year survival rates for over 700 million people living in extreme poverty worldwide.
To maintain OralVision’s proprietary aspects, we can utilize a layered IP strategy to protect both the device and its software. We will privatize our federated learning model, the HIPAA-compliant training data it receives, and its parameters so our competitors cannot incorporate them. In addition, we can also patent OralVision's novel hardware configuration and design elements to prevent others from attempting to create similar, cost-effective devices.
5. Validation and Progress: How have you validated your innovation, technology or processes? What progress have you made in developing your innovation?
Due to financial limitations and strict Institutional Review Board (IRB) regulations, it is currently not feasible to validate the OralVision prototype in a clinical trial with oral cavity cancer patients. However, our team was able to validate accuracy and other important reliability benchmarks for OralVision's federated neural network model through an in-silico experimental trial, finding that it outscored major competitors in many important metrics.
For instance, our federated learning model was able to achieve an identification accuracy of 87.15%, a ROC-AUC Score of 0.9417, and an F1 score of 0.865. Meanwhile, VELScope, our main competitor, was only able to manage an accuracy of 53% in a separate experimental trial. Since we are one of the first companies in the intraoral cancer diagnostics market to implement AI, industry standard ROC-AUC and F1 scores aren’t publicly available, but both of the scores we found for OralVision are considered above average for a high-precision medical device. 
We utilized numerous techniques while developing our ML model to get this high accuracy rate. First, we augmented our training data using geometric and lighting transformations. We rotated, flipped, and distorted the images while also modifying the brightness values during training. Additionally, we used DenseNet121 as our model architecture due to its enhanced ability to form neural connections, with our model being priorly trained via industry standard libraries to be able to effectively identify edges, curves, and textures, which is very important when detecting differences in oral images. We also added special systems to ensure reliability and to prevent overfitting, such as L2 regularization, which ensured no specific decision points were given too much weight in the decision-making process. Then, we dropped out 30-40% of our neurons in each training step to ensure redundancy and ensure detection of multiple visual features of oral cancer. Lastly, we used multi-step, gradual training to maximize accuracy. We initially trained only a head layer, later unfreezing the rest of the model to gain more accuracy with this multi-phase training. When we detected that our accuracy began to plateau, we reduced our learning rate by a factor of 5. Combining all of these techniques, with a cutoff for determination at 0.5, allowed us to create a highly accurate diagnostic model.
However, we realized that solely basing our model on publicly available training data would allow competitors to create comparable models by using similar techniques. This is why we transformed our ML model into a federated learning model that allows us to stay ahead of competitors by constantly improving our model with new, HIPAA-compliant patient data that competitors cannot copy. With this methodology, the initial prototype for our innovation (OralVision V1) is fully functional and ready for mass production.
6. Market: Describe your customers and your target segments. What is important to them? What is the size of the opportunity? Is the buyer or payer different from the customer in this market? Describe the industry ecosystem.
Our primary customers are physicians working at local dental clinics and Federally Qualified Health Centers (FQHCs) that serve underprivileged populations. These doctors are often the first to discover potentially malignant oral lesions during routine exams, positioning them as a major adoption channel for intraoral cancer screening tools. Some factors that are highly important for these customers are workflow efficiency, diagnostic accuracy, and patient welfare. Most physicians will prefer that novel screening solutions integrate seamlessly into existing routines without wasting too much time or money, factors that are crucial in the fast-paced, lucrative medical industry. Furthermore, dentists will be more inclined to adopt an imaging technology if it has shown a superior degree of accuracy in experimental trials to ensure that their patients won't be misdiagnosed and suffer avoidable medical consequences. However, while dental physicians are OralVision's main customers, the buyers are usually clinical administrators, who are mainly interested in maximizing profits and limiting diagnostic errors to avoid costly lawsuits. Thus, in order to encourage clinical administration to purchase OralVision for their clinics and persuade doctors to adopt the device in lieu of existing alternatives, our company will pursue multi-segment marketing, creating specialized advertising campaigns for our target segments based on their individual priorities and interests. The opportunity size for an oral cancer screening device is significant, as the global market for intraoral imaging is valued at approximately 535 million USD. Currently, the oral cancer diagnostics industry is built around large dental imaging hardware manufacturers, with dentists and oncologists acting as the main channels for diffusion. Despite the rise of digital dentistry in the past decade, most competitors haven't incorporated new AI technologies in their devices yet. With OralVision's use of novel deep learning methods for diagnostics, our company has the potential to completely revolutionize the intraoral diagnostics market.
7. Competition: What competes with your innovation, and how does your innovation compare? What are the advantages and disadvantages of your innovation? What is your positioning?
OralVision's most significant competitors in the oral diagnostics market are the VELScope Vx and the ViziLite PRO Oral Lesion Screening System. These devices utilize blue light to excite fluorophore molecules in the mucous membrane, resulting in abnormal oral tissue emitting a distinct fluorescence. While these existing solutions have been successful in improving lesion visibility, they cannot accurately differentiate between benign and malignant growths and ultimately rely on the physician's naked eye to provide a specific diagnosis. Moreover, both the VELScope Vx and the ViziLite PRO can cost over $2,000 upfront, with necessary accessories bringing that price even higher. This exorbitant pricing alienates many clinics in underprivileged areas from accessing essential intraoral diagnostic technology, contributing to disproportionately high oral cavity cancer rates. While OralVision and its competitors all have the same goal of assisting physicians with oral cancer diagnosis, our innovation's novel software and cost-effective design make it revolutionary in the diagnostics market. Instead of simply illuminating abnormal tissue, OralVision takes multiple photos of a patient's oral cavity and feeds them into a comprehensive federated neural network that our company developed and trained. Our innovation has the capability to provide highly accurate clinical diagnoses and iteratively refine model parameters based on aggregated HIPAA-compliant patient data, giving us a significant edge over market competitors that haven't even considered integrating machine learning with intraoral cancer diagnostics yet. In addition, OralVision utilizes cost-effective hardware, enabling our company to produce the device at a relatively low marginal cost and sell it at a highly competitive price that's more accessible to underserved communities. The only notable disadvantage that OralVision has in comparison with existing solutions is the fact that the device is quite bulky and not ergonomically optimized. However, we have plans to make the OralVision's frame more streamlined to maximize patient comfort in future prototypes.
8. Go-to-Market: How will you attract and sell to customers? Who are the best initial or pilot customers? Is the market best served through direct sales, distribution, licensing, strategic partnerships or other strategies?
OralVision's initial market strategy will prioritize outreach towards administration at local dental clinics and Federally Qualified Health Centers (FQHCs) to establish strategic pilot partnerships. Clinics that participate in this pilot program will receive our device at a discounted rate and provide insightful, HIPAA-compliant training data for OralVision's federated-learning-based diagnostic model, allowing us to attract a large preliminary customer base through penetrative pricing while also improving OralVision's software for future global commercialization. Most major medical diagnostic corporations employ market strategies like Hardware as a Service (HaaS), where participating clinics are required to pay an extortionate monthly fee in continue using a medical device. However, due to OralVision's cost-effective design, our company is able to practice an outright sales approach, providing clinics with a cheap, high quality diagnostic device free of additional fees. This competitive pricing strategy incentivizes clinics to switch over from HaaS-based competitors, effectively increasing our market share.
9. Business Model: What are your key revenues and costs? What are the pricing and costs to deliver one product or service unit?
OralVision's most significant costs come from the purchase of its primary hardware components. The device relies on a 8 GB Raspberry Pi 5 SBC that houses our federated neural network for intraoral image analysis, costing $105 per unit. Our prototype also incorporates an industrial HMI touch display, which costs $81.95 per unit. With the addition of dozens of other miscellaneous electronic components, the total manufacturing cost for OralVision comes out to approximately $500 per unit, which is below the average production cost for prominent MedTech competitors. Our company plans to utilize FedEx's standard 2Day shipping program for domestic logistics, since our medical device is below the 150 pound weight floor for specialized shipping and doesn't incorporate any thermosensitive components that require a climate-controlled shipping environment. Distribution to local clinics and FQHCs under our pilot partnership program via FedEx 2Day will cost about $20.00 per unit. Once OralVision has penetrated the domestic market, our company plans for global commercialization, with international logistics being handled by CENCORA World Courier. The 2 most significant costs associated with global distribution include import tariffs and 3PL fees, which can vary substantially based on the country and shipping volume. OralVision will generate the majority of its revenue through direct sale of our prototype to clinical partners at a highly competitive price. On average, large corporations in the medical device market have consistent profit margins of 20-30%, so OralVision will be priced at about $750 per unit to attain a similar margin, assuming that the approximate cost of goods sold (COGS) is $520. This price is over 3.5 times cheaper than existing market alternatives like the VELScope Vx and the ViziLite PRO Oral Lesion Screening System, incentivizing clinics to adopt OralVision instead and ultimately increasing our gross revenue.
10. Fundraising: What funds do you need to get started, and how will you use these funds? How much will it cost to develop the product and roll it out? What different sources will you pursue for funding, and why are these a fit?
OralVision will require approximately $28,000 in seed funding to ensure regulatory compliance, support preliminary manufacturing efforts, and facilitate distribution to pilot clinics. To start, we will need $6,517 to cover the application fee for FDA 510(k) premarket clearance, which is required for Class II medical devices like OralVision to be commercialized in the US. Once we've met federal regulations, our company will allocate $20,000 to capital investment in industrial-grade 3D printers and electronic components to kickstart mass production of our prototype. Finally, we plan to distribute our product in a timely manner to pilot partners through FedEx 2Day, which will cost about $1800. To acquire these funds, we plan to apply to entrepreneurship programs like the NSF SBIR/STTR grant and Google’s Startup Accelerator. These programs are equity free and provide access to expert mentorship and Cloud TPUs, allowing us to maximize our profits while also improving OralVision’s software and design.