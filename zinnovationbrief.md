1. Elevator Pitch:
Pitch your innovation, sharing its essence, impact, customers and business potential.
Oral cavity cancers are highly treatable when caught early, but almost 70% of cases are diagnosed too late due to clinical uncertainty and a lack of accessible screening tools, leading to over 170,000 deaths annually. OralVision is an intraoral, deep-learning-powered diagnostic device designed to change this unfortunate reality. The device captures high resolution images of the oral cavity and analyzes them in real time using a pre-trained neural network that can identify malignant tissue patterns oblivious to the naked eye. By integrating noninvasive imaging with advanced artificial intelligence, our innovation is capable of providing physicians with highly accurate diagnostic insights, allowing for earlier clinical referrals and therapeutic intervention. Moreover, with its use of inexpensive, yet powerful components, OralVision has the potential to be mass produced and distributed at a much lower marginal cost than existing solutions, contributing to improved 5-year survival rates, especially in marginalized low-income communities.




2. Team: How did your team form? What role will each team member play? What motivated you to make this innovation? What special capabilities, resources or experiences do your team members bring?
Team OralVision was formed in response to rising rates of oral cavity and pharyngeal cancers in North Texas, which have disproportionately affected members of our community living underprivileged medical deserts like South Dallas with limited access to proper diagnostic technologies. We saw the hardships that these people had to go through firsthand from volunteer experiences, motivating us to pursue an engineering-based solution that could make a meaningful impact on public health systems in these areas. Alan brings nearly 2 years of experience in oncology research and business management, allowing him to effectively facilitate model pretraining and product commercialization. Zayan brings significant expertise in the development of deep-learning models using TensorFlow for previous projects, making him well suited to facilitate development of OralVision's ML model and user interface. Abdullah contributes over 3 years of experience in CAD, electrical engineering, and prototype design, positioning him to lead the design of OralVision's hardware.



3. Opportunity: What issue or pain point does your innovation address?

Over the past decade, oral cavity cancer rates have skyrocketed across the United States as a result of increased human papillomavirus (HPV) exposure. While oral cancer is quite treatable when caught early, nearly 70% of cases are diagnosed in the later stages, largely because malignant oral mucosa lesions are often misdiagnosed as visually similar benign conditions like canker sores and fibromas. In fact, a recent study publishexd in MDPI's Healthcare journal showed that 54% of oral cancer cases were misdiagnosed by dental practitioners and senior students, exemplifying the scale of diagnostic errors in the field of oral oncology. This diagnostic gap is only exacerbated by inequitable access to advanced healthcare technologies in underprivileged communities, with over 30% of people living in these areas reported to have limited access to proper dental care. Even in Federally Qualified Health Centers (FQHCs), which are dedicated to serving the healthcare needs of low-income populations, cancer screening rates are substantially lower than the national average. Unfortunately, this combination of diagnostic uncertainty and healthcare disparities leads to over 170,000 deaths annually across the world, raising debates over whether existing diagnostic solutions are adequate to address the silent threat that oral cavity cancers pose. Most oral cancer imaging devices utilize fluorescence spectroscopy to illuminate abnormal tissue, but these methods cannot differentiate between benign and malignant lesions. Therefore, final diagnoses ultimately depend on unreliable visual examinations or expensive biopsy procedures that are often not feasibly accessible for people living in impoverished areas. Moreover, these fluorescence-based devices can cost over $2,000 per unit, further alienating clinics that serve low-income communities from utilizing affordable diagnostic tools. OralVision aims to ameliorate these issues by offering a highly accurate, deep-learning-based imaging tool that is over 3 times cheaper than alternatives, ultimately contributing to decreased oral cavity cancer rates.


750 4. Innovation: Describe your innovation, its design and your technology. How does it work? What is new or proprietary about the innovation? How does it meet needs and resolve pain points? What impact does your innovation create for individual users and for humankind? Describe this qualitatively and quantitatively. How can new or proprietary aspects be protected and made valuable by one or more methods such as a patent, trade secret, copyright or otherwise competitively defensible configuration?
[System Overview – 1:10–1:55 | Visual: labeled 3D model or exploded diagram of device]
The control center for OralVision’s imaging device is a XIAO-ESP32-C6 microcontroller, a low-cost yet powerful solution to reduce costs while maintaining the technical capabilities of larger, more expensive controllers. The image is taken using an OV5642 5 MP Image Sensor with SPI compatibility for high-bandwidth image data transfer to the microcontroller. Additionally, an anti-fog nano coating is applied to the camera lens to prevent moisture in the mouth from harming the internal components. To minimize user error, the entire system uses a single medical-grade momentary push button to control image streaming and capturing. The power is regulated using a 5V voltage regulator to prevent current spikes when alternate charging methods are used. The regulator accepts multiple power sources, including USB-C (with a port for easy charging access), AA batteries, and solar power (for extremely low-income areas with minimal electrical infrastructure). The imager also ships with rechargeable Nickel Metal Hydride batteries to prevent thermal runaway during transportation. The entire system is then enveloped in a sterilization wrap to prevent bacteria and microbes from entering the device. The prototype’s housing is held together using a snap-fit mechanism to provide easy access to the electronics for battery replacements and software updates. 
OralVision employs a three-layer distributed architecture optimized for low-latency medical imaging while considering the physical and resource constraints of its target clients. First, the sensing layer consists of an Arducam OV5642 5-MP image sensor and a 140-degree camera lens to maximize coverage and image quality while minimizing image capture latency. Next, the processing layer consists of the ESP32-C6 with a WiFi 802.11b/g/n transceiver to wirelessly transmit image data to the inference layer utilizing a Flask WiFi Access Point on a Raspberry Pi 5. The Pi has 16GB of SDRAM for model loading and communicates with the device using Flask and the RESTful API. Once the image data is transmitted, the Raspberry Pi analyzes the image with TensorFlow Lite and outputs the possible diseases and their probabilities.


Yet, unlike other devices, OralVision’s machine learning algorithm can be trained and updated using federated learning, where physicians can mark real-world responses when they differ from what our model outputs. Modified weights will be sent to a global model which can be used on all client devices, improving the performance of our models. We will only be transferring the new model weights given by client devices and not any images or sensitive information, maintaining HIPAA compliance while continuously improving the primary function of the device. Additionally, physicians can update their OralVision models quickly and easily over the Internet and will be reminded periodically using the system’s internal clock to update the device’s weights. However, in low-income areas where access to the Internet may not always be feasible, the devices can continue to work with older model architectures without updating.


OralVision attempts to lower the ceiling for the diagnosis of oral malignancies by streamlining the processing pipeline. Users are not required to have any prior medical experience to utilize the device, as the minimal control system in conjunction with the software-level abstraction ensures a smooth user experience. Moreover, OralVision was designed with the limitations of its most prominent environment in mind, as it will be shipped with features such as rechargeable batteries and solar power capabilities pre-installed, lowering the barrier to usage and expediting the setup timeline. OralVision enables physicians in low-income areas without the practical nor technical experience in dentistry or stomatology to diagnose their patients effortlessly.


In order to maintain our device’s proprietary aspects, we will be privatizing our machine learning model and its weights so that our competitors cannot utilize the data we have. By using federated learning, we can ensure our model consistently stays ahead of competitors by using private data. Additionally, we will patent the instrument and the processor’s design to prevent others from attempting to create similarly cost-effective devices. We will also be aggressively expanding in our early years to improve our model and incorporate our device to as many places as possible, gaining a competitive edge over the rest of the market.




For communication protocols with OralVision, we used SPI and Wifi. We decided on SPI over UART and I2C because of its faster speeds and continuous data transfer, minimizing latency and allowing for high resolution images to be transmitted quickly. We then transfer our images to our ML interface wirelessly using Wifi 5, where our Federated Learning model then processes the images and outputs our results to the screen on our interface. When a device processes an image, it alters neural parameters to improve the accuracy of our main model, which clients can download from our website for software updates.

Our ML model performs far better than competitors. We attained an overall identification accuracy of 87.15%, with a high ROC-AUC Score of 0.9417 and an F1 score of 0.8655, while VELScope, our main competitor, was shown to only manage an accuracy of 53% in experimental trials.

We used a variety of techniques while developing our ML model to get this high accuracy rate. Firstly, we augmented our limited training data using geometric and lighting transformations. Additionally, we used DenseNet121 as our model architecture due to its enhanced ability to form neural connections. We also added systems to ensure reliability and to prevent overfitting. We used L2 regularization to ensure our model was not overfitted on our data by ensuring no specific decision points were given too large of a weight in the decision making process.  Lastly, we used multi-step gradual training to maximize accuracy. We initially trained only a head layer, later unfreezing the rest of the model to gain more accuracy with this multi-phase training. 
However, we realized that solely basing our model on publicly available training data would allow competitors to easily create comparable models using similar techniques. Therefore, we transformed our standard ML model into a federated learning model that allows for constant inputs of new, HIPAA-compliant patient data that competitors cannot copy. This shift to federated learning allows us to negate biases that may have been present in our training data, improve our model’s parameters, and stay ahead of major market competitors.

Thank you for considering OralVision.


450 5. Validation and Progress: How have you validated your innovation, technology or processes? What progress have you made in developing your innovation?

Due to financial limitations and strict Institutional Review Board (IRB) regulations, it is currently not feasible to validate the OralVision prototype in a clinical trial with oral cavity cancer patients. However, our team was able to validate accuracy and other important reliability benchmarks for OralVision's federated neural network model through an in-silico experimental trial, finding that it outscored major competitors in many important metrics.
	Our ML model performs far better than competitors. We had an accuracy of 87.15%, with an ROC-AUC Score of 0.9417 and an F1 score of 0.8655, while VELScope, our main competitor, was only able to manage an accuracy of 53%. Since we are the first in the intraoral cancer diagnostics market to implement AI, industry standard ROC AUC and F1 scores aren’t publicly available, but both scores are considered above average for a high precision medical device. 
We used a variety of techniques while developing our ML model to get this high accuracy rate. Firstly, we augmented our training data using geometric and lighting transformations. We rotated, flipped, and distorted the images while also increasing and decreasing the brightness of our images while training. Additionally, we used DenseNet121 as our model architecture due to its enhanced ability to form neural connections. We also initially trained our model using industry standard libraries to be able to effectively identify edges, curves, and textures which is very important when detecting differences in oral images. We also added systems to ensure reliability and to prevent overfitting. We used L2 regularization to ensure our model was not overfitted on our data by ensuring no specific decision points were given too large of a weight in the decision making process. We also dropped out 30 to 40% of our neurons in each training step to ensure redundancy and make sure we detected multiple visual features of oral cancer. Lastly, we used multi-step, gradual training to maximize accuracy. We initially trained only a head layer, later unfreezing the rest of the model to gain more accuracy with this multi-phase training. Additionally, when we detected that our accuracy began to plateau, we reduced our learning rate by a factor of 5. Combining all of these techniques allowed us to arrive at an extremely accurate model.
However, we realized that solely basing our model on publicly available training data would allow competitors to create comparable models by using similar techniques. This is why we turned our ML model into a Federated learning model that allows us to stay ahead of competitors by constantly improving our model with new, HIPAA-compliant private data that competitors cannot copy. Additionally, using federated learning allows us to bypass biases that may have been present in our training data.


6. Market: Describe your customers and your target segments. What is important to them? What is the size of the opportunity? Is the buyer or payer different from the customer in this market? Describe the industry ecosystem.
Our primary customers are physicians working at local dental clinics and Federally Qualified Health Centers (FQHCs) that serve underprivileged populations. These doctors are often the first to discover potentially malignant oral lesions during routine exams, positioning them as a major adoption channel for intraoral cancer screening tools. Some factors that are highly important for these customers are workflow efficiency, diagnostic accuracy, and patient welfare. Most physicians will prefer that novel screening solutions integrate seamlessly into existing routines without wasting too much time or money, factors that are crucial in the fast-paced, lucrative medical industry. Furthermore, dentists will be more inclined to adopt an imaging technology if it has shown a superior degree of accuracy in experimental trials to ensure that their patients won't be misdiagnosed and suffer avoidable medical consequences. However, while dental physicians are OralVision's main customers, the buyers are usually clinical administrators, who are mainly interested in maximizing profits and limiting diagnostic errors to avoid costly lawsuits. Thus, in order to encourage clinical administration to purchase OralVision for their clinics and persuade doctors to adopt the device in lieu of existing alternatives, our company will pursue multi-segment marketing, creating specialized advertising campaigns for our target segments based on their individual priorities and interests. The opportunity size for an oral cancer screening device is significant, as the global market for intraoral imaging is valued at approximately 1.27 billion USD. Currently, the oral cancer diagnostics industry is built around large dental imaging hardware manufacturers, with dentists and oncologists acting as the main channels for diffusion. Despite the rise of digital dentistry in the past decade, most competitors haven't incorporated new AI technologies in their devices yet. With OralVision's use of novel deep learning methods for diagnostics, our company has the potential to completely revolutionize the intraoral diagnostics market.

7. Competition: What competes with your innovation, and how does your innovation compare? What are the advantages and disadvantages of your innovation? What is your positioning?
OralVision's most significant competitors in the oral diagnostics market are the VELScope Vx and the ViziLite PRO Oral Lesion Screening System. These devices utilize blue light to excite fluorophore molecules in the mucous membrane, resulting in abnormal oral tissue emitting a distinct fluorescence. While these existing solutions have been successful in improving lesion visibility, they cannot accurately differentiate between benign and malignant growths and ultimately rely on the physician's naked eye to provide a specific diagnosis. Moreover, both the VELScope Vx and the ViziLite PRO can cost over $2,000 upfront, with necessary accessories bringing that price even higher. This exorbitant pricing alienates many clinics in underprivileged areas from accessing essential intraoral diagnostic technology, contributing to disproportionately high oral cavity cancer rates. While OralVision and its competitors all have the same goal of assisting physicians with oral cancer diagnosis, our innovation's novel software and cost-effective design make it revolutionary in the diagnostics market. Instead of simply illuminating abnormal tissue, OralVision takes multiple photos of a patient's oral cavity and feeds them into a comprehensive federated neural network that our company developed and trained. Our innovation has the capability to provide highly accurate clinical diagnoses and iteratively refine model parameters based on aggregated HIPAA-compliant patient data, giving us a significant edge over market competitors that haven't even considered integrating machine learning with intraoral diagnostics yet. In addition, OralVision utilizes cost-effective hardware, enabling our company to produce it at a relatively lower marginal cost and sell it at a highly competitive price that's more accessible to underserved communities. The only notable disadvantage that OralVision has in comparison with existing solutions is the fact that the device is quite bulky and not ergonomically optimized. However, we have plans to make the device frame more streamlined to maximize patient comfort in future prototypes.

8. Go-to-Market: How will you attract and sell to customers? Who are the best initial or pilot customers? Is the market best served through direct sales, distribution, licensing, strategic partnerships or other strategies?
OralVision's initial market strategy will prioritize outreach towards administration at local dental clinics and Federally Qualified Health Centers (FQHCs) to establish strategic pilot partnerships. Clinics that participate in this pilot program will receive our device at a discounted rate and provide insightful, HIPAA-compliant training data for OralVision's federated-learning-based diagnostic model, allowing us to attract a large preliminary customer base through penetrative pricing while also improving OralVision's software for future global commercialization. Most major medical diagnostic corporations employ market strategies like Hardware as a Service (HaaS), where participating clinics are required to pay an extortionate monthly fee in continue using a medical device. However, due to OralVision's cost-effective design, our company is able to practice an outright sales approach, providing clinics with a cheap, high quality diagnostic device free of additional fees. This competitive pricing strategy incentivizes clinics to switch over from HaaS-based competitors, effectively increasing our market share.

9. Business Model: What are your key revenues and costs? What are the pricing and costs to deliver one product or service unit?
OralVision's most significant costs come from the purchase of its primary hardware components. The device relies on a 8 GB Raspberry Pi 5 SBC that houses our federated neural network for intraoral image analysis, costing $105 per unit. Our prototype also incorporates an industrial HMI touch display, which costs $81.95 per unit. With the addition of dozens of other miscellaneous electronic components, the total manufacturing cost for OralVision comes out to approximately $500 per unit, which is below the average production cost for prominent MedTech competitors. Our company plans to utilize FedEx's standard 2Day shipping program for domestic logistics, since our medical device is below the 150 pound weight floor for specialized shipping and doesn't incorporate any thermosensitive components that require a climate-controlled shipping environment. Distribution to local clinics and FQHCs under our pilot partnership program via FedEx 2Day will cost about $15.00 per unit. Once OralVision has penetrated the domestic market, our company plans for global commercialization, with international logistics being handled by CENCORA World Courier. The 2 most significant costs associated with global distribution include import tariffs and 3PL fees, which can vary substantially based on the country and shipping volume. OralVision will generate the majority of its revenue through direct sale of our prototype to clinical partners at a highly competitive price. On average, large corporations in the medical device market have consistent profit margins of 20-30%, so OralVision will be priced at about $680 per unit to attain a similar margin, assuming that the approximate cost of goods sold (COGS) is $515. This price is over 3.5 times cheaper than existing market alternatives like the VELScope Vx and the ViziLite PRO Oral Lesion Screening System, incentivizing clinics to adopt OralVision instead and ultimately increasing our gross revenue.

10. Fundraising: What funds do you need to get started, and how will you use these funds? How much will it cost to develop the product and roll it out? What different sources will you pursue for funding, and why are these a fit?
OralVision will require approximately $28,000 in seed funding to ensure regulatory compliance, support preliminary manufacturing efforts, and facilitate distribution to pilot clinics. To start, we will need $6,517 to cover the application fee for FDA 510(k) premarket clearance, which is required for Class II medical devices like OralVision to be commercialized in the US. Once we've met federal regulations, our company will allocate $20,000 to capital investment in industrial-grade 3D printers and electronic components to kickstart mass production of our prototype. Finally, we plan to distribute our product in a timely manner to pilot partners through FedEx 2Day, which will cost about $1800. To acquire these funds, we plan to apply to entrepreneurship programs like the NSF SBIR/STTR grant and Google’s Startup Accelerator. These programs are equity free and provide access to expert mentorship and Cloud TPUs, allowing us to maximize our profits while also improving OralVision’s software and design.